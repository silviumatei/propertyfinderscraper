{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: un-comment the line below in case you are not sure if your environment has all the packages installed\n",
    "#!pip install grequests bs4 lxml pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages we need in order to perform the extraction\n",
    "import grequests\n",
    "from grequests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# EDIT THIS TO YOUR LOCAL FOLDER\n",
    "#os.chdir('C:\\\\path\\\\to\\\\the\\\\projects\\\\folder')\n",
    "\n",
    "# Create a variable to store today's date which will be used to automatically name the files (if ran every day)\n",
    "today = datetime.today().strftime('%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################FUNCTIONS\n",
    "\n",
    "############## FUNCTION 1: TO SCRAPE THE FIRST SEARCH PAGE FOR EACH CITY\n",
    "# CITY CODES\n",
    "# 1-dubai\n",
    "# 2-umm al quwain\n",
    "# 3-ras al khaimah\n",
    "# 4-sharjah\n",
    "# 5-ajman\n",
    "# 6-abu dhabi\n",
    "# 7-fujairah\n",
    "# 8-al ain\n",
    "\n",
    "\n",
    "def firstpage():\n",
    "    u = 'https://www.propertyfinder.ae/en/search?c=2&l={}&ob=mr&page=1&rp=y&t=1'\n",
    "    city = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    url = []\n",
    "    \n",
    "    for i in city:\n",
    "        temp_url = u.format(i)\n",
    "        url.append(temp_url)\n",
    "    print(url)\n",
    "    return url\n",
    "\n",
    "############# FUNCTION TO EXTRACT THE NUMBER OF PAGES AND SAVE IT IN A PYTHON LIST\n",
    "\n",
    "def getnoofpages(alist):\n",
    "    import re\n",
    "    \n",
    "    p = []\n",
    " \n",
    "    req = (grequests.get(url) for url in alist)\n",
    "    response = grequests.imap(req, size = 1)\n",
    "    \n",
    "    for r in response:\n",
    "\n",
    "        try:\n",
    "            soup = BeautifulSoup(r.text, 'lxml')\n",
    "            temp = soup.find('div', class_= 'property-header__list-count property-header__list-count--new ge_resultsnumber text--size2 text--color1 text--normal').text\n",
    "            temp = re.findall('[\\d]*', temp)\n",
    "            temp = ''.join(temp)\n",
    "            p.append(temp)            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "############ FUNCTION TO GENERATE THE LINKS TO ALL THE SEARCH PAGES\n",
    "\n",
    "def genopage(a2list):\n",
    "    city = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    m = [a2list]\n",
    "    u = 'https://www.propertyfinder.ae/en/search?c=2&l={}&ob=mr&page={}&rp=y&t=1'\n",
    "    url = []\n",
    "    \n",
    "    for c, v in zip(city, range(len(a2list))):   \n",
    "        n = a2list[v]\n",
    "        print(n)\n",
    "        for g in range(1, n):\n",
    "            url1 = u.format(c, g)\n",
    "            url.append(url1)\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### WE SAVE THE LIST OF PROPERTIES IN EACH CITY INTO VARIABLE e\n",
    "e = getnoofpages(firstpage())\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## THESE ARE LIST COMPREHENSION OPERATIONS TO FINALISE AND FORMAT THE LIST\n",
    "e = list(map(int, e))                                     # CONVERT TO INTEGERS\n",
    "e = [e1 / 25 for e1 in e]                                 # DIVIDE BY 25\n",
    "e = [int(e1) for e1 in e]                                 # FORCE THE VALUES INTO INTEGERS (NATURAL NUMBERS)\n",
    "e = [e1 + 2 for e1 in e]                                  # ADD 2\n",
    "f = genopage(e)                                           # GENERATE THE LIST OF ALL LINKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### CONVERT THE LIST TO A PANDAS DATAFRAME, GIVE THE NAME 'Links' TO THE COLUMN AND THEN SHOW THE DATAFRAME\n",
    "data = pd.DataFrame(f)\n",
    "data.columns = ['Links']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# SAVE THE DATAFRAME TO CSV\n",
    "data.to_csv('AllPFPages-' + today + '.csv', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

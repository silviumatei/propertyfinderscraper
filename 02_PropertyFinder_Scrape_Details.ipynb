{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: un-comment the line below in case you are not sure if your environment has all the packages installed\n",
    "#!pip install numpy pandas bs4 lxml grequests --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages we need in order to perform the scraping\n",
    "import grequests\n",
    "from grequests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# EDIT THIS TO YOUR LOCAL FOLDER\n",
    "#os.chdir('C:\\\\path\\\\to\\\\the\\\\projects\\\\folder')\n",
    "\n",
    "#OPTIONAL: UNCOMMENT IF YOU RUN IT ON GOOGLE COLAB: https://colab.research.google.com/notebooks/intro.ipynb\n",
    "#os.chdir('/content/')\n",
    "\n",
    "today = datetime.today().strftime('%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################FUNCTION TO SCRAPE THE DATA FROM THE SEARCH PAGE LINKS\n",
    "def rentals(alist):\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    \n",
    "    rs = (grequests.get(url) for url in alist)\n",
    "    responses = grequests.imap(rs, size = 10)\n",
    "\n",
    "    for response in responses:\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        \n",
    "        div_tag = soup.find_all('div', {'class':'card-list__item'})\n",
    "        \n",
    "        for div in div_tag:\n",
    "\n",
    "            try:\n",
    "                title = div.find('h2', {'class':'card__title card__title-link'}).text.strip()\n",
    "            except:\n",
    "                title = None\n",
    "\n",
    "            try:\n",
    "                ttype = div.find('p', {'class':'card__property-amenity card__property-amenity--property-type'}).text.strip()\n",
    "            except:\n",
    "                ttype = None\n",
    "\n",
    "            try:\n",
    "                bedrooms = div.find('p', {'class':'card__property-amenity card__property-amenity--bedrooms'}).text.strip()\n",
    "            except:\n",
    "                bedrooms = None\n",
    "                \n",
    "            try:\n",
    "                bathrooms = div.find('p', {'class':'card__property-amenity--bathrooms'}).text.strip()\n",
    "            except:\n",
    "                bathrooms = None\n",
    "\n",
    "            try:\n",
    "                area = div.find('p', {'class':'card__property-amenity card__property-amenity--area'}).text.strip()\n",
    "            except:\n",
    "                area = None                \n",
    "                \n",
    "            try:\n",
    "                price = div.find('span', {'class':'card__price-value'}).text.strip()\n",
    "            except:\n",
    "                price = None\n",
    "                \n",
    "            try:\n",
    "                frequency = div.find('p', {'class':'card__property-amenity--bathrooms'}).text.strip()\n",
    "            except:\n",
    "                frequency = None\n",
    "\n",
    "            try:\n",
    "                location = div.find('span', {'class':'card__location-text'}).text.strip()\n",
    "            except:\n",
    "                location = None                \n",
    "\n",
    "            try:\n",
    "                link = div.find('a', {'class':'card card--clickable'})['href']\n",
    "                link = 'www.propertyfinder.ae' + link\n",
    "            except:\n",
    "                link = None\n",
    "                \n",
    "            temp_df = pd.DataFrame([[title, ttype, bedrooms, bathrooms, area, price, location, link]], \n",
    "                                   columns=['title', 'type', 'bedrooms', 'bathrooms', 'area', 'price', 'location', 'link'])\n",
    "            results = results.append(temp_df, sort=False).reset_index(drop=True)\n",
    "    sleep(randint(2,3))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD THE DAILY LIST OF LINKS\n",
    "pf = pd.read_csv('AllPFPages-' + today + '.csv', sep=',')\n",
    "\n",
    "#SHOW THE DATAFRAME FOR A QUICK INSPECTION\n",
    "pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD THE LINKS INTO LIST\n",
    "links = pf['Links'].tolist()\n",
    "\n",
    "#PRINT THE TOTAL NUMBER OF PAGES TO SCRAPE\n",
    "print(len(links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN THE SCRAPER AND ADD THE START & END TIME\n",
    "now = datetime.now()\n",
    "start_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Start Time =\", start_time)\n",
    "\n",
    "data = rentals(links)\n",
    "\n",
    "now = datetime.now()\n",
    "end_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"End Time =\", end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE THE DATAFRAME TO DISK AS .CSV\n",
    "data.to_csv('PF_Rentals-' + today + '.csv', sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
